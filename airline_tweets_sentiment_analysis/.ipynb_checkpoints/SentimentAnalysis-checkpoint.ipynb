{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "This notebook is a practice of sentiment analysis using Keras on the US airline twitter dataset available at https://www.kaggle.com/crowdflower/twitter-airline-sentiment/downloads/twitter-airline-sentiment.zip/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      "tweet_id                        14640 non-null int64\n",
      "airline_sentiment               14640 non-null object\n",
      "airline_sentiment_confidence    14640 non-null float64\n",
      "negativereason                  9178 non-null object\n",
      "negativereason_confidence       10522 non-null float64\n",
      "airline                         14640 non-null object\n",
      "airline_sentiment_gold          40 non-null object\n",
      "name                            14640 non-null object\n",
      "negativereason_gold             32 non-null object\n",
      "retweet_count                   14640 non-null int64\n",
      "text                            14640 non-null object\n",
      "tweet_coord                     1019 non-null object\n",
      "tweet_created                   14640 non-null object\n",
      "tweet_location                  9907 non-null object\n",
      "user_timezone                   9820 non-null object\n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to only look at the text data for analysing the sentiment and will restrict myself to classification of positive/neutral/negative\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"airline_sentiment\",\n",
    "    \"text\"\n",
    "]\n",
    "\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 2 columns):\n",
      "airline_sentiment    14640 non-null object\n",
      "text                 14640 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 228.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None of the rows contain nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target variable needs to be encoded as an int\n",
    "\n",
    "sentiments = {\n",
    "    \"negative\": -1,\n",
    "    \"neutral\" : 0,\n",
    "    \"positive\": 1,\n",
    "}\n",
    "\n",
    "df[\"sentiment\"] = df[\"airline_sentiment\"].apply(lambda x: sentiments[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The text needs to be cleaned so it is lower case and only contains alpha-numerica characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "lookup_table = str.maketrans({key: None for key in string.punctuation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_text\"] = df[\"text\"].apply(lambda x: x.lower().translate(lookup_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     virginamerica what dhepburn said\n",
       "1    virginamerica plus youve added commercials to ...\n",
       "2    virginamerica i didnt today must mean i need t...\n",
       "3    virginamerica its really aggressive to blast o...\n",
       "4    virginamerica and its a really big bad thing a...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"cleaned_text\"].values\n",
    "y = df[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: do i need to stratify to maintain the distribution of the target variable.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenisation\n",
    "\n",
    "We need to convert the strings into lists of encoded characters/words for keras.\n",
    "\n",
    "#### Does this include these special characters \n",
    "rev_idx[0] = 'padding_char'\n",
    "\n",
    "rev_idx[1] = 'start_char'\n",
    "\n",
    "rev_idx[2] = 'oov_char'\n",
    "\n",
    "rev_idx[3] = 'unk_char'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token=\"oov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to the training set\n",
    "tokenizer.fit_on_texts(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words are there in the vocabulary\n",
    "num_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target variable encoding\n",
    "\n",
    "Need to encode to categorical variable for multi class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_target_classes = len(df[\"sentiment\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_cat_train = to_categorical(y_train, num_classes=number_of_target_classes)\n",
    "y_cat_test = to_categorical(y_test, num_classes=number_of_target_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding for the model\n",
    "\n",
    "Tweets have a maximum character length of 140 so the maxlength of the sequences going into the model can be of length 140 with post padding to extend any tweets shorter than the maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 100 # You're allowed 280 characters in twitter, as we're using words probably could reduce this\n",
    "\n",
    "X_train_pad = pad_sequences(X_train, max_length, padding=\"post\")\n",
    "X_test_pad = pad_sequences(X_test, max_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10248, 100)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, GRU, LSTM, Dropout, BatchNormalization\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimensions = 300 # number of dimensions for the word vector embeddings\n",
    "number_of_classes = 3 # positive/neutral/negative\n",
    "dropout_ratio = 0.2 # % of neurons to drop out to stop overfitting\n",
    "vocabulary_size = num_words # the number of words found in the train set which have been encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(max_length,))\n",
    "\n",
    "embedding = Embedding(input_dim=vocabulary_size, output_dim=embedding_dimensions, input_length=max_length)(inputs)\n",
    "x = LSTM(32, dropout=dropout_ratio, recurrent_dropout=dropout_ratio)(embedding)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "#x = Dropout(dropout_ratio)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "outputs = Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "model.compile(RMSprop(lr=0.05),\n",
    "             \"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8198 samples, validate on 2050 samples\n",
      "Epoch 1/20\n",
      "8198/8198 [==============================] - 80s 10ms/step - loss: 0.9363 - acc: 0.6212 - val_loss: 0.9676 - val_acc: 0.6122\n",
      "Epoch 2/20\n",
      "8198/8198 [==============================] - 75s 9ms/step - loss: 0.9212 - acc: 0.6300 - val_loss: 0.9402 - val_acc: 0.6122\n",
      "Epoch 3/20\n",
      "8198/8198 [==============================] - 75s 9ms/step - loss: 0.9210 - acc: 0.6300 - val_loss: 0.9807 - val_acc: 0.6122\n",
      "Epoch 4/20\n",
      "8198/8198 [==============================] - 76s 9ms/step - loss: 0.9187 - acc: 0.6300 - val_loss: 0.9351 - val_acc: 0.6122\n",
      "Epoch 5/20\n",
      "8198/8198 [==============================] - 77s 9ms/step - loss: 0.9180 - acc: 0.6300 - val_loss: 0.9376 - val_acc: 0.6122\n",
      "Epoch 6/20\n",
      "8198/8198 [==============================] - 78s 9ms/step - loss: 0.9181 - acc: 0.6300 - val_loss: 0.9405 - val_acc: 0.6122\n",
      "Epoch 7/20\n",
      "8198/8198 [==============================] - 77s 9ms/step - loss: 0.9177 - acc: 0.6300 - val_loss: 0.9380 - val_acc: 0.6122\n",
      "Epoch 8/20\n",
      "8198/8198 [==============================] - 78s 10ms/step - loss: 0.9169 - acc: 0.6299 - val_loss: 0.9513 - val_acc: 0.6122\n",
      "Epoch 9/20\n",
      "8198/8198 [==============================] - 76s 9ms/step - loss: 0.9171 - acc: 0.6300 - val_loss: 0.9491 - val_acc: 0.6122\n",
      "Epoch 10/20\n",
      "8198/8198 [==============================] - 77s 9ms/step - loss: 0.9183 - acc: 0.6300 - val_loss: 0.9554 - val_acc: 0.6122\n",
      "Epoch 11/20\n",
      "8198/8198 [==============================] - 77s 9ms/step - loss: 0.9173 - acc: 0.6300 - val_loss: 0.9361 - val_acc: 0.6122\n",
      "Epoch 12/20\n",
      "8198/8198 [==============================] - 77s 9ms/step - loss: 0.9159 - acc: 0.6300 - val_loss: 0.9359 - val_acc: 0.6122\n",
      "Epoch 13/20\n",
      "8198/8198 [==============================] - 77s 9ms/step - loss: 0.9169 - acc: 0.6300 - val_loss: 0.9378 - val_acc: 0.6122\n",
      "Epoch 14/20\n",
      "8198/8198 [==============================] - 80s 10ms/step - loss: 0.9184 - acc: 0.6300 - val_loss: 0.9484 - val_acc: 0.6122\n",
      "Epoch 15/20\n",
      "8198/8198 [==============================] - 82s 10ms/step - loss: 0.9172 - acc: 0.6292 - val_loss: 0.9363 - val_acc: 0.6122\n",
      "Epoch 16/20\n",
      "8198/8198 [==============================] - 81s 10ms/step - loss: 0.9049 - acc: 0.6300 - val_loss: 0.9814 - val_acc: 0.6122\n",
      "Epoch 17/20\n",
      "8198/8198 [==============================] - 85s 10ms/step - loss: 0.8769 - acc: 0.6244 - val_loss: 0.8775 - val_acc: 0.6078\n",
      "Epoch 18/20\n",
      "8198/8198 [==============================] - 81s 10ms/step - loss: 0.9059 - acc: 0.6303 - val_loss: 0.9357 - val_acc: 0.6122\n",
      "Epoch 19/20\n",
      "8198/8198 [==============================] - 83s 10ms/step - loss: 0.9117 - acc: 0.6321 - val_loss: 0.9453 - val_acc: 0.6122\n",
      "Epoch 20/20\n",
      " 448/8198 [>.............................] - ETA: 1:11 - loss: 0.9635 - acc: 0.6027"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_pad, \n",
    "          y_cat_train,\n",
    "          batch_size=16,\n",
    "          epochs=20,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
